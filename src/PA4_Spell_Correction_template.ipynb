{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3i3m9JjeM5U5"
      },
      "source": [
        "# **Programming Assessment \\#4**\n",
        "\n",
        "Names: ABERIN, Shawn,   LIM, Kyle,  SINGSON, Raymond\n",
        "\n",
        "More information on the assessment is found in our Canvas course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxtmCAZwNoeU"
      },
      "source": [
        "# **Load Data**\n",
        "\n",
        "*While you don't have to separate your code into blocks, it might be easier if you separated loading your data from actually implementation of your code. Consider placing all loading of data into the code block below.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      error  count         P\n",
            "0       e|i    917  0.023469\n",
            "1       a|e    856  0.021908\n",
            "2       i|e    771  0.019732\n",
            "3       e|a    749  0.019169\n",
            "4       a|i    559  0.014307\n",
            "...     ...    ...       ...\n",
            "1582     |c      1  0.000026\n",
            "1583     |a      1  0.000026\n",
            "1584     |'      1  0.000026\n",
            "1585    w|       1  0.000026\n",
            "1586   t|t       1  0.000026\n",
            "\n",
            "[1587 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# The code is defining a function called `make_p` that takes a DataFrame `df` as input.\n",
        "# lang must contain a column 'count' that contains number types\n",
        "#load error data\n",
        "\n",
        "import pandas as pd\n",
        "def make_p(pd):\n",
        "    total = pd['count'].sum()\n",
        "    inv = 1/total\n",
        "    pd['P'] = pd['count']*inv\n",
        "    return pd\n",
        "x=''\n",
        "\n",
        "with open(\"count_1edit.txt\", \"r\") as f:\n",
        "    x = f.read().splitlines()\n",
        "gen = (dat.split('\\t') for dat in x)\n",
        "data = [(rec[0],int(rec[1]))for rec in gen]\n",
        "err = pd.DataFrame.from_records(data, columns=['error', 'count'])\n",
        "err = make_p(err)\n",
        "\n",
        "print(err)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CbvxU2oTM4IV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to\n",
            "[nltk_data]     C:\\Users\\matth\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#loading corpus files\n",
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "# nltk.corpus.gutenberg.fileids()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting all documents from NLTK's Project Gutenberg Collection...\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "import string\n",
        "print(\"Extracting all documents from NLTK's Project Gutenberg Collection...\")\n",
        "all_words = Counter()\n",
        "for filename in nltk.corpus.gutenberg.fileids():\n",
        "  words = [word.lower() for word in nltk.corpus.gutenberg.words(filename) if word not in string.punctuation]\n",
        "  all_words.update(words)\n",
        "lang = pd.DataFrame.from_dict(all_words, orient='index').reset_index()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           word  count             P\n",
            "0          emma    866  3.892499e-04\n",
            "1            by   8512  3.825976e-03\n",
            "2          jane    303  1.361925e-04\n",
            "3        austen      3  1.348441e-06\n",
            "4          1816      1  4.494802e-07\n",
            "...         ...    ...           ...\n",
            "42307  endowing      1  4.494802e-07\n",
            "42308   delving      1  4.494802e-07\n",
            "42309  germinal      1  4.494802e-07\n",
            "42310   blither      1  4.494802e-07\n",
            "42311  ushering      1  4.494802e-07\n",
            "\n",
            "[42312 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "lang = lang.rename(columns={'index':'word', 0:'count'})\n",
        "lang = make_p(lang)\n",
        "\n",
        "print(lang)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8YCZLi-N0uR"
      },
      "source": [
        "# **Noisy Channel Model Implementation**\n",
        "\n",
        "*Again, you don't have to follow this directly, but consider placing your implementation of the model in the code block below.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VqKjpUrkOSnC"
      },
      "outputs": [],
      "source": [
        "# %pip install editdistpy\n",
        "from editdistpy import damerau_osa as ld\n",
        "\n",
        "def candidates(input, all_words):\n",
        "      # 1 edit distance away from word\n",
        "      if input in all_words: return [input]\n",
        "      d = 1\n",
        "      candidate_list = [w for w in all_words if ld.distance(input,w,d) > -1]\n",
        "      return candidate_list\n",
        "\n",
        "#are we still using this?\n",
        "def spell_correct(candidate_list):\n",
        "      n=2\n",
        "      \n",
        "      probable = df.loc[candidate_list].sort_values(['P'], ascending=False).head(n)\n",
        "      return list(probable.index), probable['P']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Kyle's error trace\n",
        "def calculate_edit_type_and_edit(input_word, candidate_word):\n",
        "    if len(input_word) == len(candidate_word):\n",
        "        # Check for substitution\n",
        "        diff_count = 0\n",
        "        edit_type = \"sub\"\n",
        "        edit = \"\"\n",
        "        for i in range(len(input_word)):\n",
        "            if input_word[i] != candidate_word[i]:\n",
        "                diff_count += 1\n",
        "                edit = input_word[i] + \"|\"\n",
        "                edit += candidate_word[i]\n",
        "        if diff_count == 1:\n",
        "            return edit_type, edit\n",
        "\n",
        "    elif len(input_word) + 1 == len(candidate_word):\n",
        "        # Check for insertion\n",
        "        edit_type = \"ins\"\n",
        "        edit = \"\"\n",
        "        i, j = 0, 0\n",
        "        if candidate_word[0:-1] == input_word:\n",
        "            edit +=  input_word[-1] + \"|\" + candidate_word[-2] + candidate_word[-1]\n",
        "            return edit_type, edit\n",
        "        else:\n",
        "            while i < len(input_word) and j < len(candidate_word):\n",
        "                if input_word[i] != candidate_word[j]:\n",
        "                    edit += input_word[j-1] + \"|\" + input_word[j-1] + candidate_word[j]\n",
        "                    j += 1\n",
        "                else:\n",
        "                    i += 1\n",
        "                    j += 1\n",
        "            if j == len(candidate_word):\n",
        "                return edit_type, edit\n",
        "\n",
        "    elif len(input_word) - 1 == len(candidate_word):\n",
        "        # Check for deletion\n",
        "        edit_type = \"del\"\n",
        "        edit = \"\"\n",
        "        i, j = 0, 0\n",
        "        if input_word[0:-1] == candidate_word:\n",
        "            edit += input_word[-1] + input_word[-2] + \"|\" + candidate_word[-1]\n",
        "            return edit_type, edit\n",
        "        else:\n",
        "            while i < len(input_word) and j < len(candidate_word):\n",
        "                if input_word[i] != candidate_word[j]:\n",
        "                    edit += input_word[i-1] + input_word[i] + \"|\" + candidate_word[i - 1]\n",
        "                    i += 1\n",
        "                else:\n",
        "                    i += 1\n",
        "                    j += 1\n",
        "        if i == len(input_word):\n",
        "            return edit_type, edit\n",
        "\n",
        "    # Check for transposition\n",
        "    if len(input_word) == len(candidate_word) and input_word != candidate_word:\n",
        "        for i in range(len(input_word) - 1):\n",
        "            if input_word[i] == candidate_word[i + 1] and input_word[i + 1] == candidate_word[i]:\n",
        "                edit_type = \"trans\"\n",
        "                edit = candidate_word[i:i+2] + \"|\" + input_word[i:i+2]\n",
        "                return edit_type, edit\n",
        "\n",
        "    return None, None  # No valid edit type found\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Word candidate edit_type  edit          P(c)    P(w|c)  P(c) x P(w|c)\n",
            "0  theee     these       sub   e|s  1.281019e-03  0.000589   7.540611e-07\n",
            "1  theee     there       sub   e|r  2.867684e-03  0.000307   8.807157e-07\n",
            "2  theee     three       sub   e|r  5.519617e-04  0.000307   1.695171e-07\n",
            "3  theee     theme       sub   e|m  8.090644e-06  0.000102   8.282593e-10\n",
            "4  theee      thee       del  ee|e  2.160651e-03  0.000000   0.000000e+00\n",
            "5  theee    theefe       ins  e|ef  4.494802e-07  0.000461   2.070648e-10\n"
          ]
        }
      ],
      "source": [
        "#main function\n",
        "test_input = input(\"User Input: \")\n",
        "test_input = test_input.lower()\n",
        "c = candidates(test_input, all_words)\n",
        "if c[0] == test_input:\n",
        "    print(\"Word is spelled correctly\")\n",
        "else:\n",
        "    df = pd.DataFrame(columns=['Word', 'candidate', 'edit_type', 'edit', 'P(c)', 'P(w|c)', 'P(c) x P(w|c)'])\n",
        "    #show all candidates\n",
        "    i = 0\n",
        "    for candidate in c:\n",
        "        #get probability of word\n",
        "        wordP = lang.loc[lang['word'] == candidate]\n",
        "        wordP = wordP.iloc[0]['P']\n",
        "        edit_type, edit = calculate_edit_type_and_edit(test_input, candidate)\n",
        "        #get probability of error\n",
        "        try:\n",
        "            editP = err.loc[err['error'] == edit]\n",
        "            editP = editP.iloc[0]['P']\n",
        "        except:\n",
        "            editP = 0\n",
        "        temp = pd.DataFrame({'Word' : test_input, 'candidate' : candidate, 'edit_type' : edit_type, 'edit' : edit, 'P(c)' : wordP, 'P(w|c)' : editP, 'P(c) x P(w|c)' : (wordP * editP)}\n",
        "                            , index=[i])\n",
        "        df = pd.concat([df, temp])\n",
        "        i += 1\n",
        "\n",
        "df.sort_values('P(c) x P(w|c)')\n",
        "print(df)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "8f4b3deeac0a5ce6c43bde11bfee6a0d7b0549337061a7646d07811ade3818cd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
